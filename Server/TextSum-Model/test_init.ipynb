{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "path=\"./model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This library implements the generic methods of the model library PreTrainedModel.\n"
     ]
    }
   ],
   "source": [
    "myInput=(\n",
    "    \"The bare PEGASUS Model outputting raw hidden-states without any specific head on top. This model inherits from PreTrainedModel. Check the superclass documentation for the generic methods the library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads etc.)\"\n",
    ")\n",
    "input=tokenizer(myInput,max_length=1024,return_tensors=\"pt\",truncation=True)\n",
    "output = model.generate(\n",
    "    input[\"input_ids\"],\n",
    "    max_length=100,\n",
    "    min_length=10\n",
    "    )\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(path)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# path = \"./model\"\n",
    "# tokenizer.save_pretrained(path)\n",
    "# model.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This library implements the generic methods of the superclass PreTrainedModel, which implements the methods of the pre-trained model, pruning heads, and embeddings, as well as the methods of the pre-trained model, pruning heads, and embeddings, which implements the methods of the pre-trained model, pruning heads, and embeddings, as well as the methods of the pre-trained model, pruning heads, and embeddings, which implements the methods of the pre-trained model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "path=\"./model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(path)\n",
    "\n",
    "myInput=(\n",
    "    \"The bare PEGASUS Model outputting raw hidden-states without any specific head on top. This model inherits from PreTrainedModel. Check the superclass documentation for the generic methods the library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads etc.)\"\n",
    ")\n",
    "input=tokenizer(myInput,max_length=1024,return_tensors=\"pt\",truncation=True)\n",
    "output = model.generate(\n",
    "    input[\"input_ids\"],\n",
    "    max_length=100,\n",
    "    min_length=50\n",
    "    )\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
